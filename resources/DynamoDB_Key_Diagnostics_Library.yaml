AWSTemplateFormatVersion: 2010-09-09
Transform: 'AWS::Serverless-2016-10-31'
Parameters:
  KinesisSourceStreamShardCount:
    Type: Number
    Default: 4
    MinValue: 4
    Description: The number of shards for the Kinesis source stream where the Key Diagnostics client writes to.
  HotKeyLogsGroupName:
    Type: String
    Default: hot-keys-logs-group
    Description: CloudWatch Logs Group name for storing hot key log streams.
  HotKeyLogsStreamPrefix:
    Type: String
    Default: hot-keys-logs-stream
    Description: CloudWatch Logs Stream name for recording hot key logs.
  HotKeyAlarmPeriod:
    Type: Number
    Default: 51600
    Description: The time period used for evaluation, in seconds, in multiples of 60.
  HotKeyAlarmThreshold:
    Type: Number
    Default: 500
    Description: The threshold to alarm on a key for being hot.

Resources:
  KeyDiagnosticsRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - kinesisanalytics.amazonaws.com
                - firehose.amazonaws.com
                - lambda.amazonaws.com
            Action: 'sts:AssumeRole'
      Path: /
      Policies:
        - PolicyName: KinesisAnalyticsAppInput
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - kinesis:DescribeStream
                  - kinesis:GetShardIterator
                  - kinesis:GetRecords
                Resource: !Sub "arn:aws:kinesis:${AWS::Region}:${AWS::AccountId}:stream/*"
        - PolicyName: FirehoseOutput
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - firehose:DescribeDeliveryStream
                  - firehose:PutRecord
                  - firehose:PutRecordBatch
                  - s3:AbortMultipartUpload
                  - s3:GetBucketLocation
                  - s3:GetObject
                  - s3:ListBucket
                  - s3:ListBucketMultipartUploads
                  - s3:PutObject
                Resource:
                  - !Sub "arn:aws:firehose:${AWS::Region}:${AWS::AccountId}:deliverystream/*"
                  - !Sub "${AggregatedResultBucket.Arn}/*"
        - PolicyName: LambdaOutput
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - lambda:InvokeFunction
                  - lambda:GetFunctionConfiguration
                Resource: !Sub "arn:aws:lambda:${AWS::Region}:${AWS::AccountId}:function:*"

  SourceStream:
    Type: AWS::Kinesis::Stream
    Properties:
      ShardCount:
        Ref: KinesisSourceStreamShardCount
      StreamEncryption:
        EncryptionType: KMS
        # This is a KMS alias that points to an AWS Managed CMK provided by Kinesis.
        KeyId: alias/aws/kinesis

  AnalyticsApplication:
    Type: AWS::KinesisAnalytics::Application
    Properties:
      ApplicationDescription: Kinesis Analytics Application for DynamoDB Key Diagnostics Library
      Inputs:
        - NamePrefix: SOURCE_DIAGNOSTICS_STREAM
          InputSchema:
            RecordColumns:
              - Name: StartTime
                SqlType: BIGINT
                Mapping: $.start_time
              - Name: EndTime
                SqlType: BIGINT
                Mapping: $.end_time
              - Name: IO
                SqlType: DOUBLE
                Mapping: $.IO
              - Name: Operation
                SqlType: VARCHAR(16)
                Mapping: $.Operation
              - Name: TableName
                SqlType: VARCHAR(255)
                Mapping: $.Table
              - Name: HashKey
                SqlType: VARCHAR(255)
                Mapping: '$.KeyValues[0:].name'
              - Name: HashKeyValue
                SqlType: VARCHAR(2048)
                Mapping: '$.KeyValues[0:].value'
            RecordFormat:
              RecordFormatType: JSON
              MappingParameters:
                JSONMappingParameters:
                  RecordRowPath: $
          KinesisStreamsInput:
            ResourceARN: !GetAtt SourceStream.Arn
            RoleARN: !GetAtt KeyDiagnosticsRole.Arn
      ApplicationCode: |
        -- INTERMEDIATE_STREAM to convert start time and end time to TIMESTAMP
        -- This isn't necessary, but we can reuse this INTERMEDIATE_STREAM for other analytics streams
        CREATE OR REPLACE STREAM "INTERMEDIATE_STREAM" (
          "StartTime" TIMESTAMP NOT NULL,
          "EndTime" TIMESTAMP NOT NULL,
          "TableName" VARCHAR(255) NOT NULL,
          "Operation" VARCHAR(16) NOT NULL,
          "IO" DOUBLE NOT NULL,
          "HashKey" VARCHAR(255) NOT NULL,
          "HashKeyValue" VARCHAR(2048) NOT NULL
        );
        -- Corresponding 'pump' to insert data into the INTERMEDIATE_STREAM
        CREATE OR REPLACE PUMP "INPUT_PUMP" AS
          INSERT INTO "INTERMEDIATE_STREAM"
            SELECT STREAM
              TO_TIMESTAMP("StartTime"),
              TO_TIMESTAMP("EndTime"),
              "TableName",
              "Operation",
              "IO",
              "HashKey",
              "HashKeyValue"
        FROM "SOURCE_DIAGNOSTICS_STREAM_001"; -- This refers to the actual Kinesis Stream

        -- SECOND_AGGREGATED_STREAM aggregates key records to per-second results
        CREATE OR REPLACE STREAM "SECOND_AGGREGATED_STREAM" (
          "Second" timestamp  NOT NULL,
          "TableName" varchar(255) NOT NULL,
          "HashKey" varchar(255) NOT NULL,
          "HashKeyValue" varchar(2048) NOT NULL,
          "Operation" varchar(16) NOT NULL,
          "TotalIO" DOUBLE NOT NULL);
        -- The corresponding pump to insert second-aggregated data from the INTERMEDIATE_STREAM
        -- All columns are aggregated using the GROUP BY, and summed over the IO consumed during each second.
        CREATE OR REPLACE PUMP "SECOND_PUMP" AS
          INSERT INTO "SECOND_AGGREGATED_STREAM"
            SELECT STREAM
              FLOOR(Max("EndTime") TO SECOND),
              "TableName",
              "HashKey",
              "HashKeyValue",
              "Operation",
              SUM("IO") as TotalIO
            FROM "INTERMEDIATE_STREAM"
            GROUP BY
              FLOOR("INTERMEDIATE_STREAM".ROWTIME TO SECOND),
              "TableName",
              "HashKey",
              "HashKeyValue",
              "Operation";

        -- MINUTE_AGGREGATED_STREAM aggregates key records to per-second results
        CREATE OR REPLACE STREAM "MINUTE_AGGREGATED_STREAM" (
          "Minute" timestamp NOT NULL,
          "TableName" varchar(255) NOT NULL,
          "HashKey" varchar(255) NOT NULL,
          "HashKeyValue" varchar(2048) NOT NULL,
          "Operation" varchar(16) NOT NULL,
          "TotalIO" DOUBLE NOT NULL);
        -- The corresponding pump to insert second-aggregated data from the INTERMEDIATE_STREAM
        -- All columns are aggregated using the GROUP BY, and summed over the IO consumed during each second.
        CREATE OR REPLACE PUMP "MINUTE_PUMP" AS
          INSERT INTO "MINUTE_AGGREGATED_STREAM"
            SELECT STREAM
              MONOTONIC(FLOOR("Second" TO MINUTE)),
              "TableName",
              "HashKey",
              "HashKeyValue",
              "Operation",
              SUM("TotalIO")
            FROM "SECOND_AGGREGATED_STREAM"
            GROUP BY MONOTONIC(FLOOR("Second" TO MINUTE)),
              "TableName",
              "HashKey",
              "HashKeyValue",
              "Operation";
  AnalyticsOutputFirehose:
    Type: AWS::KinesisAnalytics::ApplicationOutput
    Properties:
      ApplicationName: !Ref AnalyticsApplication
      Output:
        Name: SECOND_AGGREGATED_STREAM
        DestinationSchema:
          RecordFormatType: JSON
        KinesisFirehoseOutput:
          ResourceARN: !GetAtt FirehoseS3.Arn
          RoleARN: !GetAtt KeyDiagnosticsRole.Arn
    DependsOn:
      - AnalyticsApplication
  FirehoseS3:
    Type: AWS::KinesisFirehose::DeliveryStream
    Properties:
      DeliveryStreamType: DirectPut
      S3DestinationConfiguration:
        BucketARN: !GetAtt AggregatedResultBucket.Arn
        BufferingHints:
          IntervalInSeconds: '60'
          SizeInMBs: '20'
        CompressionFormat: UNCOMPRESSED
        Prefix: diagnostics/
        RoleARN: !GetAtt KeyDiagnosticsRole.Arn
        EncryptionConfiguration:
          KMSEncryptionConfig:
            AWSKMSKeyARN: !Sub "arn:aws:kms:${AWS::Region}:${AWS::AccountId}:alias/aws/s3"
  AggregatedResultBucket:
      Type: AWS::S3::Bucket
      Properties:
        BucketEncryption:
          ServerSideEncryptionConfiguration:
            - ServerSideEncryptionByDefault:
                SSEAlgorithm: aws:kms
                # This is a KMS alias that points to an AWS Managed CMK provided by S3.
                KMSMasterKeyID: alias/aws/s3
  AnalyticsOutputLambda:
    Type: AWS::KinesisAnalytics::ApplicationOutput
    Properties:
      ApplicationName: !Ref AnalyticsApplication
      Output:
        Name: MINUTE_AGGREGATED_STREAM
        DestinationSchema:
          RecordFormatType: JSON
        LambdaOutput:
          ResourceARN: !GetAtt HotKeyLoggerLambdaFunction.Arn
          RoleARN: !GetAtt KeyDiagnosticsRole.Arn
  HotKeyLoggerLambdaFunction:
    Type: AWS::Serverless::Function
    Properties:
      CodeUri: ./resources/python/src/diagnostics/hot_key_logger_lambda.py
      Handler: hot_key_logger_lambda.lambda_handler
      Runtime: python2.7
      Description: An AWS Lambda function that emits hot key metrics and logs the hot keys.
      MemorySize: 128
      Timeout: 30
      Policies:
        - CloudWatchPutMetricPolicy: {}
      Environment:
        Variables:
          HOT_KEY_LOGS_GROUP_NAME:
            Ref: HotKeyLogsGroupName
          HOT_KEY_LOGS_STREAM_PREFIX:
            Ref: HotKeyLogsStreamPrefix
  HeatAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      ComparisonOperator: GreaterThanOrEqualToThreshold
      EvaluationPeriods: 1
      MetricName: Breaching key total IO
      Namespace: DynamoDBKeyDiagnosticsLibrary
      Period:
        Ref: HotKeyAlarmPeriod
      Threshold:
        Ref: HotKeyAlarmThreshold
      Statistic: Maximum
    DependsOn:
      - HotKeyLoggerLambdaFunction
  HotKeyLogGroup:
    Type: AWS::Logs::LogGroup
    Properties:
      LogGroupName:
        Ref: HotKeyLogsGroupName

Outputs:
  SourceStreamName:
    Description: Name of the source data stream (Kinesis Data Stream).
    Value: !Ref SourceStream
  KinesisAnalyticAppName:
    Description: Name of Kinesis Data Analytics Application.
    Value: !Ref AnalyticsApplication
  S3BucketName:
    Description: Name of S3 bucket for storing aggregated data from Kinesis Analytics.
    Value: !Ref AggregatedResultBucket
  HeatAlarmName:
    Description: Name of AWS CloudWatch hot key alarm.
    Value: !Ref HeatAlarm
